{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Install dataset from ISIC\n"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-22T23:04:11.064991Z","iopub.status.busy":"2024-10-22T23:04:11.064650Z","iopub.status.idle":"2024-10-22T23:04:27.005843Z","shell.execute_reply":"2024-10-22T23:04:27.004849Z","shell.execute_reply.started":"2024-10-22T23:04:11.064952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting isic-cli\n","  Downloading isic_cli-11.0.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: click>=8 in /opt/conda/lib/python3.10/site-packages (from isic-cli) (8.1.7)\n","Collecting django-s3-file-field-client>=1.0.0 (from isic-cli)\n","  Downloading django_s3_file_field_client-1.0.1-py3-none-any.whl.metadata (2.7 kB)\n","Collecting girder-cli-oauth-client<1.0.0 (from isic-cli)\n","  Downloading girder_cli_oauth_client-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: humanize in /opt/conda/lib/python3.10/site-packages (from isic-cli) (4.9.0)\n","Collecting isic-metadata>=1.2.0 (from isic-cli)\n","  Downloading isic_metadata-4.0.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from isic-cli) (10.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from isic-cli) (21.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from isic-cli) (2.32.3)\n","Collecting retryable-requests (from isic-cli)\n","  Downloading retryable_requests-0.1.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from isic-cli) (13.7.1)\n","Requirement already satisfied: sentry-sdk in /opt/conda/lib/python3.10/site-packages (from isic-cli) (2.15.0)\n","Requirement already satisfied: tenacity in /opt/conda/lib/python3.10/site-packages (from isic-cli) (8.3.0)\n","Collecting authlib (from girder-cli-oauth-client<1.0.0->isic-cli)\n","  Downloading Authlib-1.3.2-py2.py3-none-any.whl.metadata (3.9 kB)\n","Collecting pyxdg (from girder-cli-oauth-client<1.0.0->isic-cli)\n","  Downloading pyxdg-0.28-py2.py3-none-any.whl.metadata (567 bytes)\n","Requirement already satisfied: pydantic>=2.4 in /opt/conda/lib/python3.10/site-packages (from isic-metadata>=1.2.0->isic-cli) (2.9.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->isic-cli) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->isic-cli) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->isic-cli) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->isic-cli) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->isic-cli) (2024.8.30)\n","Requirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from retryable-requests->isic-cli) (0.10.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->isic-cli) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->isic-cli) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->isic-cli) (0.1.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (4.12.2)\n","Requirement already satisfied: cryptography in /opt/conda/lib/python3.10/site-packages (from authlib->girder-cli-oauth-client<1.0.0->isic-cli) (42.0.8)\n","Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (1.16.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (2.22)\n","Downloading isic_cli-11.0.0-py3-none-any.whl (30 kB)\n","Downloading django_s3_file_field_client-1.0.1-py3-none-any.whl (3.2 kB)\n","Downloading girder_cli_oauth_client-0.4.0-py3-none-any.whl (8.1 kB)\n","Downloading isic_metadata-4.0.0-py3-none-any.whl (26 kB)\n","Downloading retryable_requests-0.1.2-py3-none-any.whl (7.5 kB)\n","Downloading Authlib-1.3.2-py2.py3-none-any.whl (225 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading pyxdg-0.28-py2.py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyxdg, django-s3-file-field-client, retryable-requests, isic-metadata, authlib, girder-cli-oauth-client, isic-cli\n","Successfully installed authlib-1.3.2 django-s3-file-field-client-1.0.1 girder-cli-oauth-client-0.4.0 isic-cli-11.0.0 isic-metadata-4.0.0 pyxdg-0.28 retryable-requests-0.1.2\n"]}],"source":["!pip install isic-cli"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T23:08:00.802585Z","iopub.status.busy":"2024-10-22T23:08:00.802141Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["If you have been granted special permissions, logging in with `isic user login` might return more data.\n","\n","\u001b[2KDownloading images (and metadata) (100,000 total) \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 61%\u001b[0m \u001b[36m0:41:36\u001b[0m"]}],"source":["!isic image download images/ --limit 100000"]},{"cell_type":"markdown","metadata":{},"source":["### Download data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv('images/metadata.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"Current device: {torch.cuda.current_device()}\")\n","    print(f\"Device name: {torch.cuda.get_device_name()}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Load initial weights\n","\n","We're using transfer learning to improve accuracy on our model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torchvision.models import resnet50, ResNet50_Weights\n","\n","# Using the latest weights: https://pytorch.org/vision/stable/models.html#initializing-pre-trained-models\n","weights = ResNet50_Weights.DEFAULT\n","\n","model = resnet50(weights=weights).to(device)\n","\n","transform = weights.transforms()\n","\n","# Freeze the pretrained parameters\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Allow training last layer\n","model.fc = torch.nn.Linear(2048, 4).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Load into train & test datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","from PIL import Image \n","\n","class CustomDataset(Dataset):\n","    def __init__(self, df, transform = None):\n","        self.df = df\n","        self.transform = transform\n","        self.class_labels = {\n","            'benign': 0,\n","            'malignant': 1,\n","            'indeterminate/benign': 2,\n","            'indeterminate/malignant': 3\n","        }\n","    \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        # get the corresponding image\n","        image_id = row[\"isic_id\"]\n","        img_path = f\"/kaggle/working/images/{image_id}.jpg\"\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        # get the label\n","        label_str = row['benign_malignant']\n","        label = self.class_labels[label_str] # convert label to number\n","        \n","        return image, torch.tensor(label, dtype=torch.long)\n","        \n","    def __len__(self):\n","        return len(self.df)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import os\n","\n","train_df, test_df = train_test_split(\n","    df,\n","    train_size=0.9\n",")\n","\n","train_dataset = CustomDataset(df=train_df, transform=transform)\n","test_dataset = CustomDataset(df=test_df, transform=transform)"]},{"cell_type":"markdown","metadata":{},"source":["### Load data into mini batches"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","BATCH_SIZE=32\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count())\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count())"]},{"cell_type":"markdown","metadata":{},"source":["### Loss function & optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n","loss_fn = torch.nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{},"source":["### Train the model!!!\n","The fun part :)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from timeit import default_timer as timer\n","start_time = timer()\n","\n","epochs = 3\n","\n","results = {\"train_loss\": [],\n","           \"train_acc\": [],\n","           \"test_loss\": [],\n","           \"test_acc\": []}\n","\n","for epoch in range(epochs):\n","    model.train()\n","\n","    train_loss, train_acc = 0, 0\n","    \n","    for batch, (X, y) in enumerate(train_dataloader):\n","        # Device agnoistic code\n","        X, y = X.to(device), y.to(device)\n","        \n","        # Forward pass\n","        y_logits = model(X)\n","        \n","        # Calculate loss\n","        loss = loss_fn(y_logits, y)\n","        train_loss += loss.item()\n","        \n","        pred_label = y_logits.argmax(dim=1)\n","        train_acc += (pred_label==y).sum().item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Keep track of the current batch\n","        if batch % 100 == 0:\n","            print(f\"Epoch {epoch+1}/{epochs} | Batch {batch}/{len(train_dataloader)}\")\n","\n","    test_loss, test_acc = 0, 0\n","    \n","    # Evaluate the model\n","    model.eval()\n","    with torch.inference_mode():\n","        for batch, (X, y) in enumerate(test_dataloader):\n","            X, y = X.to(device), y.to(device)\n","\n","            y_logits = model(X)\n","            loss = loss_fn(y_logits, y)\n","\n","            test_loss += loss.item()\n","\n","            pred_label = y_logits.argmax(dim=1)\n","            test_acc += (pred_label==y).sum().item()\n","\n","    train_loss = train_loss / len(train_dataloader)\n","    test_loss = test_loss / len(test_dataloader)\n","    \n","    train_acc = train_acc / (len(train_dataloader) * train_dataloader.batch_size)\n","    test_acc = test_acc / (len(test_dataloader) * test_dataloader.batch_size)\n","    \n","    results[\"train_loss\"].append(train_loss)\n","    results[\"train_acc\"].append(train_acc)\n","    results[\"test_loss\"].append(test_loss)\n","    results[\"test_acc\"].append(test_acc)\n","    \n","    print(f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss} | Train accuracy: {train_acc} | Test accuracy: {test_acc}\")\n","\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_loss_curves(results):\n","    \"\"\"Plots training curves of a results dictionary.\n","\n","    Args:\n","        results (dict): dictionary containing list of values, e.g.\n","            {\"train_loss\": [...],\n","             \"train_acc\": [...],\n","             \"test_loss\": [...],\n","             \"test_acc\": [...]}\n","    \"\"\"\n","    loss = results[\"train_loss\"]\n","    test_loss = results[\"test_loss\"]\n","\n","    accuracy = results[\"train_acc\"]\n","    test_accuracy = results[\"test_acc\"]\n","\n","    epochs = range(len(results[\"train_loss\"]))\n","\n","    plt.figure(figsize=(15, 7))\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, loss, label=\"train_loss\")\n","    plt.plot(epochs, test_loss, label=\"test_loss\")\n","    plt.title(\"Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n","    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n","    plt.title(\"Accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_loss_curves(results)"]},{"cell_type":"markdown","metadata":{},"source":["### Save model\n","So we can do inference later"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from pathlib import Path \n","\n","models = Path(\"models\")\n","\n","models.mkdir(parents=True, exist_ok=True)\n","\n","model_name = \"model.pth\"\n","PATH = models / model_name\n","\n","torch.save(model.state_dict(), f=PATH)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
